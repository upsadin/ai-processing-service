spring:
  application:
    name: ai-processing-service
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://localhost:5432/ai_pipeline}
    username: ${SPRING_DATASOURCE_USERNAME:ai_user}
    password: ${SPRING_DATASOURCE_PASSWORD:ai_pass}
    driver-class-name: org.postgresql.Driver
  liquibase:
      change-log: classpath:db/changelog.xml
      enabled: true
  data:
    jdbc:
      repositories:
        enabled: true
  kafka:
    bootstrap-servers: ${SPRING_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
    topics:
      incoming: ai.processing.raw
      outgoing: ai.candidate.filtered
      processing-dlq: ai.processing.business.dlq
    groups-id:
      consumer: ai-processing
      dlq: ai-processing-dlq
    producer:
      transaction-id-prefix: ai-processing-tx-${random.value}-
      acks: all
      properties:
        enable:
          idempotence: true
        max:
          in:
            flight:
              requests:
                per:
                  connection: 5
    consumer:
      isolation-level: read_committed
      enable-auto-commit: false
      concurrency: 3
  cache:
    type: caffeine
    cache-names: prompts
    caffeine:
      spec: maximumSize=500,expireAfterWrite=5m
  lifecycle:
    timeout-per-shutdown-phase: 30s
server:
  shutdown: graceful

ai:
  api:
    key: ${OPENAI_API_KEY:not_set}
    base-url: https://api.openai.com/v1/chat/completions
    model-name: gpt-4.1-nano
    temperature: 0.1

management:
  endpoints:
    web:
      exposure:
        include: health, info, prometheus
  metrics:
    tags:
      application: ai-processing-service
    distribution:
      percentiles-histogram:
        ai.request.duration: true
      slo:
        ai.request.duration: 500ms, 1s, 2s, 5s
  tracing:
    sampling:
      probability: 1.0